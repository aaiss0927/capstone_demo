import os
import json
import shutil
from glob import glob
from sklearn.model_selection import train_test_split

# --- ê²½ë¡œ ì„¤ì • ---
SOURCE_IMAGE_DIR = 'Sample/01.ì›ì²œë°ì´í„°'
SOURCE_LABEL_DIR = 'Sample/02.ë¼ë²¨ë§ë°ì´í„°'
OUTPUT_BASE_DIR = 'YOLO/data/custom'

# --- í´ë˜ìŠ¤ ë§¤í•‘ (ì›ë³¸ JSONì˜ categories ë°°ì—´ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©) ---
# 'none' (categories_id: 3) í´ë˜ìŠ¤ë¥¼ ì œì™¸í–ˆìŠµë‹ˆë‹¤.
CATEGORIES = [
    {"category_index": 1, "category_name": "fl"},
    {"category_index": 2, "category_name": "sm"},
]
# í—ˆìš©ëœ ì¹´í…Œê³ ë¦¬ ID ëª©ë¡ (1ê³¼ 2ë§Œ í—ˆìš©)
ALLOWED_CATEGORY_IDS = [c['category_index'] for c in CATEGORIES]

# --- ë¶„í•  ë¹„ìœ¨ ---
TRAIN_RATIO = 0.8  # 80%
VAL_RATIO = 0.1    # 10%
TEST_RATIO = 0.1   # 10%
RANDOM_SEED = 42

def create_output_dirs():
    """í•„ìš”í•œ ì¶œë ¥ ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    for split in ['train', 'val', 'test']:
        os.makedirs(os.path.join(OUTPUT_BASE_DIR, 'images', split), exist_ok=True)
        os.makedirs(os.path.join(OUTPUT_BASE_DIR, 'labels'), exist_ok=True)
    print(f"ì¶œë ¥ í´ë” êµ¬ì¡° ìƒì„± ì™„ë£Œ: {OUTPUT_BASE_DIR}/{{images, labels}}/{{train, val, test}}")

def process_and_split_data():
    """ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ë¶„í• í•˜ì—¬ ì¶œë ¥ í´ë”ì— ë³µì‚¬ ë° í†µí•© JSONì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    # 1. ëª¨ë“  JSON íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
    all_json_paths = []
    for root, _, files in os.walk(SOURCE_LABEL_DIR):
        for file in files:
            if file.endswith('.json'):
                all_json_paths.append(os.path.join(root, file))
    
    if not all_json_paths:
        print("Error: '02.ë¼ë²¨ë§ë°ì´í„°'ì—ì„œ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2. Train/Val/Test ë¶„í•  (ì´ ë¶€ë¶„ì€ ë³€ê²½ ì—†ìŒ)
    test_val_size = VAL_RATIO + TEST_RATIO
    train_paths, test_val_paths = train_test_split(
        all_json_paths, 
        test_size=test_val_size, 
        random_state=RANDOM_SEED
    )
    
    val_paths, test_paths = train_test_split(
        test_val_paths, 
        test_size=TEST_RATIO / test_val_size,
        random_state=RANDOM_SEED
    )
    
    print(f"\në°ì´í„° ë¶„í•  ê²°ê³¼:")
    print(f"Train: {len(train_paths)}ê°œ")
    print(f"Validation: {len(val_paths)}ê°œ")
    print(f"Test: {len(test_paths)}ê°œ")
    
    data_splits = {
        'train': train_paths,
        'val': val_paths,
        'test': test_paths
    }

    # 3. íŒŒì¼ ì²˜ë¦¬, ë³µì‚¬ ë° í†µí•© JSON ìƒì„±
    for split_name, json_list in data_splits.items():
        print(f"\n--- {split_name.upper()} ë°ì´í„°ì…‹ ì²˜ë¦¬ ì¤‘ ---")
        
        integrated_data = [] 
        
        for json_path in json_list:
            
            # 3-1. JSON íŒŒì¼ ë¡œë“œ
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # 3-2. ì´ë¯¸ì§€ ë³µì‚¬ (ë³€ê²½ ì—†ìŒ)
            base_filename_no_ext = os.path.splitext(os.path.basename(json_path))[0]
            img_source_path_glob = glob(os.path.join(SOURCE_IMAGE_DIR, '**', base_filename_no_ext + '.jpg'), recursive=True)
            
            if not img_source_path_glob:
                print(f"Warning: ì´ë¯¸ì§€ íŒŒì¼ '{data['image']['filename']}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            img_source_path = img_source_path_glob[0]
            
            img_dest_dir = os.path.join(OUTPUT_BASE_DIR, 'images', split_name)
            shutil.copy(img_source_path, img_dest_dir)

            # 3-3. ë°ì´í„°ë¥¼ í†µí•© ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (None í´ë˜ìŠ¤ í•„í„°ë§ ë¡œì§ ì¶”ê°€)
            
            # ì›ë³¸ ë°ì´í„°ì˜ categoriesì™€ annotationsë¥¼ ë³µì‚¬
            new_data = data.copy()
            
            # categories ë°°ì—´ì„ í•„í„°ë§ëœ ë²„ì „ìœ¼ë¡œ êµì²´
            new_data['categories'] = CATEGORIES
            
            # annotations ë°°ì—´ì—ì„œ categories_idê°€ 3ì¸ í•­ëª©(none)ì„ ì œì™¸í•˜ê³  í•„í„°ë§
            if 'annotations' in data and data['annotations']:
                filtered_annotations = [
                    ann for ann in data['annotations'] 
                    if ann.get('categories_id') in ALLOWED_CATEGORY_IDS
                ]
                new_data['annotations'] = filtered_annotations
            else:
                 # ì–´ë…¸í…Œì´ì…˜ì´ ì•„ì˜ˆ ì—†ëŠ” ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìœ ì§€
                new_data['annotations'] = []
            
            # ìœ íš¨í•œ ì–´ë…¸í…Œì´ì…˜ì´ í•˜ë‚˜ë¼ë„ ìˆê±°ë‚˜, ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ì™¸ì˜ ë©”íƒ€ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì¶”ê°€
            # ë§Œì•½ í•„í„°ë§ í›„ ì–´ë…¸í…Œì´ì…˜ì´ 0ê°œê°€ ë˜ì–´ë„, ì´ë¯¸ì§€ ë©”íƒ€ ì •ë³´ëŠ” í•„ìš”í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•©ë‹ˆë‹¤.
            integrated_data.append(new_data)
            
        # 3-4. í†µí•© JSON íŒŒì¼ ì €ì¥ (ë³€ê²½ ì—†ìŒ)
        output_json_path = os.path.join(OUTPUT_BASE_DIR, 'labels', f'annotations_{split_name}.json')
        
        with open(output_json_path, 'w', encoding='utf-8') as f:
            json.dump(integrated_data, f, indent=4, ensure_ascii=False)
            
        print(f"í†µí•© JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_json_path}")

    print("\nâœ… ëª¨ë“  ë°ì´í„° ë³€í™˜ ë° í•„í„°ë§ ì™„ë£Œ.")


if __name__ == "__main__":
    try:
        from sklearn.model_selection import train_test_split
    except ImportError:
        print("ğŸš¨ 'scikit-learn' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        print("pip install scikit-learn")
        exit()
        
    create_output_dirs()
    process_and_split_data()